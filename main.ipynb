{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sys to check the current Python executable\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# Import necessary libraries and install if they are not already installed\n",
    "import subprocess\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'numpy', 'pandas', 'opencv-python', 'Pillow', 'torch', 'torchvision',\n",
    "    'scikit-learn', 'jupyter'\n",
    "]\n",
    "\n",
    "# Install the required packages\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        install(package)\n",
    "\n",
    "# Now you can safely import the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time # for random seed\n",
    "print(\"All packages are installed and imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the id-labels mapping in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny-imagenet-200 dataset\n",
    "data_dir = \"tiny-imagenet-200\"\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "\n",
    "\n",
    "# get all of the classes whose images are in the training set\n",
    "training_class_ids = os.listdir(train_dir)\n",
    "\n",
    "# class id - class label mapping\n",
    "id_class_label_map = {}\n",
    "with open(os.path.join(data_dir, 'words.txt'), 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split('\\t')\n",
    "        class_id = line[0]\n",
    "        class_label = line[1]\n",
    "        id_class_label_map[class_id] = class_label\n",
    "\n",
    "\n",
    "# for each class in the tiny-imagenet-200 dataset, get the class label\n",
    "training_id_class_map = {}\n",
    "for class_id in training_class_ids:\n",
    "    class_label = id_class_label_map[class_id]\n",
    "    training_id_class_map[class_id] = class_label\n",
    "\n",
    "# we have 200 classes in the tiny-imagenet-200 dataset with their class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ten_random_class_ids(training_class_ids):\n",
    "    # get 10 random classes\n",
    "\n",
    "    # seed random with time\n",
    "    np.random.seed(int(time.time()))\n",
    "\n",
    "    ten_random_classes = np.random.choice(training_class_ids, 10, replace=False)\n",
    "    return ten_random_classes\n",
    "\n",
    "\n",
    "print(\"10 random classes:\")\n",
    "ten_random_classes = get_ten_random_class_ids(training_class_ids)\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. {ten_random_classes[i]} - {training_id_class_map[ten_random_classes[i]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images in the training set for each of the 10 random classes\n",
    "# class-id to class images\n",
    "training_class_images = {}\n",
    "for class_id in ten_random_classes:\n",
    "    class_images = os.listdir(os.path.join(train_dir, class_id, 'images'))\n",
    "    training_class_images[class_id] = class_images\n",
    "\n",
    "for class_id in ten_random_classes:\n",
    "    print(f\"{class_id} - {training_id_class_map[class_id]} has {len(training_class_images[class_id])} images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
